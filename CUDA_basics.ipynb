{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRMSqpFetbov",
        "outputId": "5470667a-f0c7-4ffb-bce9-e01b7edb65dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The wurlitzer extension is already loaded. To reload it, use:\n",
            "  %reload_ext wurlitzer\n"
          ]
        }
      ],
      "source": [
        "%pip install -q wurlitzer ninja\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "%load_ext wurlitzer\n",
        "\n",
        "import torch\n",
        "from torch.utils.cpp_extension import load_inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility fucntions for CUDA\n",
        "\n",
        "def load_cuda(cuda_src, cpp_src, funcs, opt=True, verbose=False, name=None):\n",
        "    \"Simple wrapper for torch.utils.cpp_extension.load_inline\"\n",
        "    if name is None: name = funcs[0]\n",
        "    flags = \"-O3 -Xptxas -O3 -Xcompiler -O3\" if opt else \"-O0 -Xptxas -O0 -Xcompiler -O0\"\n",
        "    return load_inline(cuda_sources=[cuda_src], cpp_sources=[cpp_src], functions=funcs,\n",
        "                       extra_cuda_cflags=[flags], verbose=verbose, name=name)\n",
        "\n",
        "# Utility code strings for CUDA\n",
        "\n",
        "cuda_begin = r'''\n",
        "#include <torch/extension.h>\n",
        "#include <stdio.h>\n",
        "#include <c10/cuda/CUDAException.h>\n",
        "\n",
        "#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n",
        "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
        "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
        "#define CUDA_ERR(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) exit(code);\n",
        "   }\n",
        "}\n",
        "__host__ __device__ inline unsigned int cdiv(unsigned int a, unsigned int b) { return (a+b-1)/b;}\n",
        "'''\n",
        "\n",
        "cuda_end = r'''\n",
        "torch::Tensor mat_mul(torch::Tensor A, torch::Tensor B) {\n",
        "    CHECK_INPUT(A); CHECK_INPUT(B);\n",
        "    int rows=A.size(0), columns=B.size(1), inners=A.size(1);\n",
        "    TORCH_CHECK(inners==B.size(0), \"Size mismatch!\");\n",
        "\n",
        "    auto C = torch::zeros({rows, columns}, A.options());\n",
        "    dim3 tpb(16, 16);\n",
        "    dim3 blocks(cdiv(rows, tpb.x), cdiv(columns, tpb.y));\n",
        "\n",
        "    mat_mul_naive<<<blocks, tpb>>>(\n",
        "      static_cast<float*>(A.data_ptr()), static_cast<float*>(B.data_ptr()), static_cast<float*>(C.data_ptr()),\n",
        "      rows, columns, inners);\n",
        "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "    return C;\n",
        "}\n",
        "'''\n",
        "\n",
        "cpp4python = \"torch::Tensor mat_mul(torch::Tensor A, torch::Tensor B);\"\n",
        "\n",
        "#TODO: add f string support to these to automate code gen."
      ],
      "metadata": {
        "id": "dGDXTw6d5AAB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Niave kernel\n",
        "\n",
        "mat_mul_naive = r'''\n",
        "__global__ void mat_mul_naive(const float *A, const float *B, float *C, int rows, int columns, int inners) {\n",
        "\n",
        "  // C = A @ B : (rows X inners) @ (inners X columns) -> (rows X columns)\n",
        "\n",
        "  const uint x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  const uint y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "  // if statement is necessary for when rows or columns aren't multiples of the CUDA block size.\n",
        "\n",
        "  if (x < columns && y < rows) {\n",
        "    float tmp = 0.0;\n",
        "    for (int i = 0; i < inners; ++i) {tmp += A[x * inners + i] * B[i * columns + y];}\n",
        "    C[x * columns + y] = tmp;\n",
        "  }\n",
        "}\n",
        "'''"
      ],
      "metadata": {
        "id": "YAlT_FhkDO0P"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_code = cuda_begin + mat_mul_naive + cuda_end"
      ],
      "metadata": {
        "id": "LshRfIEEIU0O"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prg = load_cuda(cuda_src=cuda_code, cpp_src=cpp4python, funcs=['mat_mul'])"
      ],
      "metadata": {
        "id": "8DpWKIqcIbUy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows = 1024\n",
        "columns = 1024\n",
        "inners = 1024\n",
        "flop = (2 * inners) * rows * columns\n",
        "A = torch.rand(rows, inners, dtype=torch.float32, device='cuda')\n",
        "B = torch.rand(inners, columns, dtype=torch.float32, device='cuda')"
      ],
      "metadata": {
        "id": "qvXjqZRGPa7_"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A.is_contiguous(), B.is_contiguous()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUq_PrlsSL65",
        "outputId": "8313f07a-f9ff-4d47-f51a-620eb165d7da"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.isclose(A@B, prg.mat_mul(A, B)).all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtMMTx9QSZqe",
        "outputId": "b538b716-3630-4b34-ff07-96241ce711f0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to time CPU/GPU events : https://developer.nvidia.com/blog/how-implement-performance-metrics-cuda-cc/"
      ],
      "metadata": {
        "id": "nJDsLUXBXGuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "se = torch.cuda.Event(enable_timing=True)\n",
        "ee = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "# Record the start time\n",
        "se.record()\n",
        "\n",
        "# Perform the matrix multiplication\n",
        "\n",
        "# C = torch.matmul(A, B)\n",
        "C = prg.mat_mul(A, B)\n",
        "\n",
        "# Record the end time\n",
        "ee.record()\n",
        "\n",
        "# Block CPU execution until the event is recorded.\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "t = se.elapsed_time(ee)\n",
        "\n",
        "print(f'GFLOPs: {flop / t*1e3 / 1e9: .6f} | Time {t:.4f} ms')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deioJ1JwVb_v",
        "outputId": "0a6f342c-efe6-47ec-831f-c5a88de13d43"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GFLOPs:  43.188403 | Time 49.7236 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cuBLAS: 1600 GFLOPS (1.3ms)\n",
        "# openBLAS: 110 GFLOPS (20ms), 2 CPU cores\n",
        "\n",
        "# niave CUDA: 43 GFLOPS (49ms)"
      ],
      "metadata": {
        "id": "KgmFdOv7Zrg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "Anp = np.random.rand(rows, inners).astype(np.float32)\n",
        "Bnp = np.random.rand(inners, columns).astype(np.float32)"
      ],
      "metadata": {
        "id": "5_uCphqoTNtu"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Acpu = A.cpu()\n",
        "Bcpu = B.cpu()\n",
        "A.device, Acpu.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M0EV003Y0CE",
        "outputId": "d9a1b994-8dcc-4278-c950-cd4cd271f578"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cuda', index=0), device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 10 _ = Acpu @ Bcpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUVpP5GPZUZS",
        "outputId": "1448e4ea-2f52-4855-b1fb-f94b79e2e3df"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19.1 ms ± 1.63 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 10 _ = Anp @ Bnp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23tKjEq2UFxJ",
        "outputId": "a34d9fc2-65f6-48c5-8f24-76f380d36f57"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20.7 ms ± 1.16 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.show_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX7RCC03UWfv",
        "outputId": "2fc7e382-9a22-45ec-f914-50b0ae9c0cbe"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openblas64__info:\n",
            "    libraries = ['openblas64_', 'openblas64_']\n",
            "    library_dirs = ['/usr/local/lib']\n",
            "    language = c\n",
            "    define_macros = [('HAVE_CBLAS', None), ('BLAS_SYMBOL_SUFFIX', '64_'), ('HAVE_BLAS_ILP64', None)]\n",
            "    runtime_library_dirs = ['/usr/local/lib']\n",
            "blas_ilp64_opt_info:\n",
            "    libraries = ['openblas64_', 'openblas64_']\n",
            "    library_dirs = ['/usr/local/lib']\n",
            "    language = c\n",
            "    define_macros = [('HAVE_CBLAS', None), ('BLAS_SYMBOL_SUFFIX', '64_'), ('HAVE_BLAS_ILP64', None)]\n",
            "    runtime_library_dirs = ['/usr/local/lib']\n",
            "openblas64__lapack_info:\n",
            "    libraries = ['openblas64_', 'openblas64_']\n",
            "    library_dirs = ['/usr/local/lib']\n",
            "    language = c\n",
            "    define_macros = [('HAVE_CBLAS', None), ('BLAS_SYMBOL_SUFFIX', '64_'), ('HAVE_BLAS_ILP64', None), ('HAVE_LAPACKE', None)]\n",
            "    runtime_library_dirs = ['/usr/local/lib']\n",
            "lapack_ilp64_opt_info:\n",
            "    libraries = ['openblas64_', 'openblas64_']\n",
            "    library_dirs = ['/usr/local/lib']\n",
            "    language = c\n",
            "    define_macros = [('HAVE_CBLAS', None), ('BLAS_SYMBOL_SUFFIX', '64_'), ('HAVE_BLAS_ILP64', None), ('HAVE_LAPACKE', None)]\n",
            "    runtime_library_dirs = ['/usr/local/lib']\n",
            "Supported SIMD extensions in this NumPy install:\n",
            "    baseline = SSE,SSE2,SSE3\n",
            "    found = SSSE3,SSE41,POPCNT,SSE42,AVX,F16C,FMA3,AVX2,AVX512F,AVX512CD,AVX512_SKX\n",
            "    not found = AVX512_KNL,AVX512_KNM,AVX512_CLX,AVX512_CNL,AVX512_ICL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.cpu_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXugJ6WTUaOz",
        "outputId": "859e7e31-574a-4f80-e570-78832f82c92e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dXcspPXdUquN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}